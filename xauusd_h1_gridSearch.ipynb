{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "import MetaTrader5 as mt5\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tf2onnx\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.python.keras.models import Sequential\n",
    "from tensorflow.python.keras.layers import Dense, Activation, Conv1D, MaxPooling1D, Dropout\n",
    "from tensorflow.python.keras.layers.recurrent import LSTM\n",
    "from tensorflow.python.keras.metrics import RootMeanSquaredError as rmse\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from datetime import timedelta, datetime\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check TensorFlow version\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "# Check GPU support\n",
    "print(len(tf.config.list_physical_devices('GPU')) > 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize MetaTrader5 for history data\n",
    "if not mt5.initialize():\n",
    "    print(\"initialize() failed, error code =\", mt5.last_error())\n",
    "    quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show terminal info\n",
    "terminal_info = mt5.terminal_info()\n",
    "print(terminal_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show file path\n",
    "file_path = terminal_info.data_path + \"\\\\MQL5\\\\Files\\\\\"\n",
    "print(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set start and end dates for history data\n",
    "end_date = datetime.now()\n",
    "start_date = end_date - timedelta(days=120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print start and end dates\n",
    "print(\"data start date=\", start_date)\n",
    "print(\"data end date=\", end_date)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get XAUUSD rates (H1) from start_date to end_date\n",
    "xauusd_rates = mt5.copy_rates_range(\"XAUUSDm\", mt5.TIMEFRAME_H1, start_date, end_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the data\n",
    "print(xauusd_rates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DataFrame\n",
    "df = pd.DataFrame(xauusd_rates)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show DataFrame head\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show DataFrame tail\n",
    "df.tail()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show DataFrame shape (the number of rows and columns in the data set)\n",
    "df.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare close prices only\n",
    "data = df.filter(['close']).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show close prices\n",
    "plt.figure(figsize=(18,10))\n",
    "plt.plot(data, 'b', label='Original')\n",
    "plt.xlabel(\"Hours\")\n",
    "plt.ylabel(\"Price\")\n",
    "plt.title(\"XAUUSD_H1\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale data using MinMaxScaler\n",
    "scaler = MinMaxScaler(feature_range=(0,1))\n",
    "scaled_data = scaler.fit_transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training size is 80% of the data\n",
    "training_size = int(len(scaled_data) * 0.80) \n",
    "print(\"training size:\", training_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create train data and check size\n",
    "train_data_initial = scaled_data[0:training_size, :]\n",
    "print(len(train_data_initial))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create test data and check size\n",
    "test_data_initial = scaled_data[training_size:, :1]\n",
    "print(len(test_data_initial))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split a univariate sequence into samples\n",
    "def split_sequence(sequence, n_steps):\n",
    "    X, y = list(), list()\n",
    "    for i in range(len(sequence)):\n",
    "        end_ix = i + n_steps\n",
    "        if end_ix > len(sequence)-1:\n",
    "            break\n",
    "        seq_x, seq_y = sequence[i:end_ix], sequence[end_ix]\n",
    "        X.append(seq_x)\n",
    "        y.append(seq_y)\n",
    "    return np.array(X), np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into samples\n",
    "time_step = 120\n",
    "x_train, y_train = split_sequence(train_data_initial, time_step)\n",
    "x_test, y_test = split_sequence(test_data_initial, time_step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape input to be [samples, time steps, features] which is required for LSTM\n",
    "x_train = x_train.reshape(x_train.shape[0], x_train.shape[1], 1)\n",
    "x_test = x_test.reshape(x_test.shape[0], x_test.shape[1], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show shape of train data\n",
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "# Show shape of test data\n",
    "x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the model function for KerasClassifier\n",
    "def create_model(optimizer='adam'):\n",
    "    model = Sequential()\n",
    "    model.add(Conv1D(filters=256, kernel_size=2, activation='relu', padding='same', input_shape=(120, 1)))\n",
    "    model.add(MaxPooling1D(pool_size=2))\n",
    "    model.add(LSTM(100, return_sequences=True))\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(LSTM(100, return_sequences=False))\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Dense(units=1, activation='sigmoid'))\n",
    "    model.compile(optimizer=optimizer, loss='mse', metrics=[rmse()])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create KerasClassifier with fixed epochs\n",
    "model = KerasClassifier(build_fn=create_model, epochs=300, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define parameter grid for Grid Search\n",
    "param_dist = {\n",
    "    'batch_size': [32, 64],\n",
    "    'optimizer': ['RMSprop', 'Adam']\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform Randomized Search with a limit on the number of parameter combinations to try (n_iter)\n",
    "random_search = RandomizedSearchCV(estimator=model, param_distributions=param_dist, n_iter=5, n_jobs=-1, cv=2)\n",
    "random_result = random_search.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show best parameters and score\n",
    "print(\"Best: %f using %s\" % (random_result.best_score_, random_result.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Measure time for model fitting with best parameters\n",
    "time_calc_start = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define EarlyStopping callback\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit model with best parameters found by Randomized Search\n",
    "best_params = random_result.best_params_\n",
    "history = model.fit(x_train, y_train, \n",
    "                    epochs=300,  # Fixed epochs\n",
    "                    validation_data=(x_test, y_test), \n",
    "                    batch_size=best_params['batch_size'], \n",
    "                    verbose=1, \n",
    "                    callbacks=[early_stopping])  # ใช้ EarlyStopping เพื่อลดเวลาการฝึก"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate time\n",
    "fit_time_seconds = time.time() - time_calc_start\n",
    "print(\"fit time =\", fit_time_seconds, \" seconds.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show iteration-loss graph for training and validation\n",
    "plt.figure(figsize = (18,10))\n",
    "plt.plot(history.history['loss'], label='Training Loss', color='b')\n",
    "plt.plot(history.history['val_loss'], label='Validation-loss', color='g')\n",
    "plt.xlabel(\"Iteration\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"LOSS\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Measure time for model fitting with best parameters\n",
    "# Show iteration-rmse graph for training and validation\n",
    "plt.figure(figsize = (18,10))\n",
    "plt.plot(history.history['root_mean_squared_error'], label='Training RMSE', color='b')\n",
    "plt.plot(history.history['val_root_mean_squared_error'], label='Validation-RMSE', color='g')\n",
    "plt.xlabel(\"Iteration\")\n",
    "plt.ylabel(\"RMSE\")\n",
    "plt.title(\"RMSE\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate training data\n",
    "model.evaluate(x_train, y_train, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate testing data\n",
    "model.evaluate(x_test, y_test, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction using training data\n",
    "train_predict = model.predict(x_train)\n",
    "plot_y_train = y_train.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show actual vs predicted (training) graph\n",
    "plt.figure(figsize=(18,10))\n",
    "plt.plot(scaler.inverse_transform(plot_y_train), color = 'b', label = 'Original')\n",
    "plt.plot(scaler.inverse_transform(train_predict), color='red', label = 'Predicted')\n",
    "plt.title(\"Prediction Graph Using Training Data\")\n",
    "plt.xlabel(\"Hours\")\n",
    "plt.ylabel(\"Price\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction using testing data\n",
    "test_predict = model.predict(x_test)\n",
    "plot_y_test = y_test.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate metrics\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform data to real values\n",
    "value1 = scaler.inverse_transform(plot_y_test)\n",
    "value2 = scaler.inverse_transform(test_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate score\n",
    "score = np.sqrt(metrics.mean_squared_error(value1,value2))\n",
    "print(\"RMSE         : {}\".format(score))\n",
    "print(\"MSE          :\", metrics.mean_squared_error(value1,value2))\n",
    "print(\"R2 score     :\",metrics.r2_score(value1,value2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show actual vs predicted (testing) graph\n",
    "plt.figure(figsize=(18,10))\n",
    "plt.plot(scaler.inverse_transform(plot_y_test), color = 'b',  label = 'Original')\n",
    "plt.plot(scaler.inverse_transform(test_predict), color='g', label = 'Predicted')\n",
    "plt.title(\"Prediction Graph Using Testing Data\")\n",
    "plt.xlabel(\"Hours\")\n",
    "plt.ylabel(\"Price\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate metrics\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform data to real values\n",
    "value1 = scaler.inverse_transform(plot_y_test)\n",
    "value2 = scaler.inverse_transform(test_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate score\n",
    "score = np.sqrt(metrics.mean_squared_error(value1,value2))\n",
    "print(\"RMSE         : {}\".format(score))\n",
    "print(\"MSE          :\", metrics.mean_squared_error(value1,value2))\n",
    "print(\"R2 score     :\",metrics.r2_score(value1,value2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show actual vs predicted (testing) graph\n",
    "plt.figure(figsize=(18,10))\n",
    "plt.plot(scaler.inverse_transform(plot_y_test), color = 'b',  label = 'Original')\n",
    "plt.plot(scaler.inverse_transform(test_predict), color='g', label = 'Predicted')\n",
    "plt.title(\"Prediction Graph Using Testing Data\")\n",
    "plt.xlabel(\"Hours\")\n",
    "plt.ylabel(\"Price\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finish\n",
    "mt5.shutdown()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
